# GESTURE RECOGNITION FOR CONTROLLING ELEMENTS OF THE SMART LAB.
## The complete task can be depicted as shown in the Figure below.
###### Note: Programming language: Python.
###### Tasks 1,2 and 3 are interlinked. Likewise Tasks 3, 4 and 5 are also interlinked.
###### Task 1: There is an algorithm with me. We need to develop it programmatically.
###### Task 2: 250*4 = 1000 gestures has to be recorded. This is to be followed by algorithm development for feature_extraction.
###### Task 3: Develop Support Vector Machine algorithm for gesture recognition.
###### Task 4: Need to collaborate with other teams in order to develop the logic for recognize the positional zone of the user in the smart lab.
###### Task 5: Need to develop a socket communication with the middleware so that the shades and the lights can be controlled via commands.
###### The last task would be regression testing of the system.
###### Deadline: 31/8/2018 for development.
###### Presentation: https://www.slideshare.net/PradeepSiddagangaiah/presentation-121805170

![Screenshot](Github.PNG)
