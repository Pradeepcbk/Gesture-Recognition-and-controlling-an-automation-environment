# GESTURE RECOGNITION FOR CONTROLLING ELEMENTS OF THE SMART LAB.
## The complete task can be depicted as shown in the Figure below.
###### Note: Programming language: Python.
###### Tasks 1,2 and 3 are interlinked. Likewise Tasks 3, 4 and 5 are also interlinked.
###### Task 1: There is an algorithm with me. We need to develop it programmatically.
###### Task 2: 250*4 = 1000 gestures has to be recorded.
###### Task 3: Completing the old algorithm and tuning the model
###### Task 4: Need to collaborate with other teams in order to develop the logic for recognize the positional zone of the user in the smart lab.
###### Task 5: Need to develop a socket communication with the middleware so that the shades and the lights can be controlled via commands.
###### The last task would be regression testing of the system.
###### Deadline: 6/7/2018 (Tentative) for development.

![alt text](https://raw.githubusercontent.com/Pradeepcbk/Gesture-Recognition-and-controlling-an-automation-environment/develop/path/to/Github.png)
